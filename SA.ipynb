{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "January_Call_DSL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Hl51BlcKBO",
        "outputId": "7a77bc52-99f4-43c3-fe59-8a3f7b7fb6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 18:48:09--  https://dbdmg.polito.it/dbdmg_web/wp-content/uploads/2021/12/DSL2122_january_dataset.zip\n",
            "Resolving dbdmg.polito.it (dbdmg.polito.it)... 130.192.163.163\n",
            "Connecting to dbdmg.polito.it (dbdmg.polito.it)|130.192.163.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18640208 (18M) [application/zip]\n",
            "Saving to: ‘DSL2122_january_dataset.zip’\n",
            "\n",
            "DSL2122_january_dat 100%[===================>]  17.78M  14.1MB/s    in 1.3s    \n",
            "\n",
            "2022-01-03 18:48:11 (14.1 MB/s) - ‘DSL2122_january_dataset.zip’ saved [18640208/18640208]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dbdmg.polito.it/dbdmg_web/wp-content/uploads/2021/12/DSL2122_january_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip DSL2122_january_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywa0_RkVcvMi",
        "outputId": "8611fe40-86f8-4851-d995-f04f486c6567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DSL2122_january_dataset.zip\n",
            "   creating: DSL2122_january_dataset/\n",
            "  inflating: DSL2122_january_dataset/development.csv  \n",
            "  inflating: __MACOSX/DSL2122_january_dataset/._development.csv  \n",
            "  inflating: DSL2122_january_dataset/sample_submission.csv  \n",
            "  inflating: __MACOSX/DSL2122_january_dataset/._sample_submission.csv  \n",
            "  inflating: DSL2122_january_dataset/evaluation.csv  \n",
            "  inflating: __MACOSX/DSL2122_january_dataset/._evaluation.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import itertools\n",
        "\n",
        "# Word2vec\n",
        "import gensim"
      ],
      "metadata": {
        "id": "MCtdhH8scz1k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRoYz7pSn8rn",
        "outputId": "03416d8e-f125-42e5-9088-a871e0638a84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/DSL2122_january_dataset/development.csv', index_col=1)"
      ],
      "metadata": {
        "id": "v0Ouiq35c-KG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "fVvVXxrQdCvz",
        "outputId": "b408f28e-f0ae-4343-f832-e0c41984067b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bee22ed6-608c-4eb3-bd16-522b3a230531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ids</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1833972543</th>\n",
              "      <td>1</td>\n",
              "      <td>Mon May 18 01:08:27 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Killandra</td>\n",
              "      <td>@MissBianca76 Yes, talking helps a lot.. going...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980318193</th>\n",
              "      <td>1</td>\n",
              "      <td>Sun May 31 06:23:17 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>IMlisacowan</td>\n",
              "      <td>SUNSHINE. livingg itttt. imma lie on the grass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994409198</th>\n",
              "      <td>1</td>\n",
              "      <td>Mon Jun 01 11:52:54 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>yaseminx3</td>\n",
              "      <td>@PleaseBeMine Something for your iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1824749377</th>\n",
              "      <td>0</td>\n",
              "      <td>Sun May 17 02:45:34 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>no_surprises</td>\n",
              "      <td>@GabrielSaporta couldn't get in to the after p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001199113</th>\n",
              "      <td>0</td>\n",
              "      <td>Tue Jun 02 00:08:07 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Rhi_ShortStack</td>\n",
              "      <td>@bradiewebbstack awww is andy being mean again...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bee22ed6-608c-4eb3-bd16-522b3a230531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bee22ed6-608c-4eb3-bd16-522b3a230531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bee22ed6-608c-4eb3-bd16-522b3a230531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            sentiment  ...                                               text\n",
              "ids                    ...                                                   \n",
              "1833972543          1  ...  @MissBianca76 Yes, talking helps a lot.. going...\n",
              "1980318193          1  ...  SUNSHINE. livingg itttt. imma lie on the grass...\n",
              "1994409198          1  ...           @PleaseBeMine Something for your iphone \n",
              "1824749377          0  ...  @GabrielSaporta couldn't get in to the after p...\n",
              "2001199113          0  ...  @bradiewebbstack awww is andy being mean again...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Ijo5ANgsNdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "JT1k-A-0sFwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUbj-x_adIfn",
        "outputId": "06b2e20c-ecf9-42da-d5a9-a9424ac72b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 224994 entries, 1833972543 to 2016018811\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0   sentiment  224994 non-null  int64 \n",
            " 1   date       224994 non-null  object\n",
            " 2   flag       224994 non-null  object\n",
            " 3   user       224994 non-null  object\n",
            " 4   text       224994 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 10.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.flag.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPORlU7trwSJ",
        "outputId": "dc773a92-286b-4012-c6ff-9d83ce4aac9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NO_QUERY'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's no need in keep on 'flag' attribute with us.\n"
      ],
      "metadata": {
        "id": "r1HPtk-dr9Ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if there's some imbalancing:"
      ],
      "metadata": {
        "id": "X-bl949InY9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_count = Counter(df.sentiment)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.bar(sentiment_count.keys(), sentiment_count.values())\n",
        "plt.title('Dataset labels distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "sz9AH2nVdKWK",
        "outputId": "452d9623-e5a3-4136-d9dd-dd2a2b1e01db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Dataset labels distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LKEYRcqqsnFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First benchmark:"
      ],
      "metadata": {
        "id": "zU2QVmUcrpbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use only the text as features.."
      ],
      "metadata": {
        "id": "Co8OH4v3vYb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(df.text)"
      ],
      "metadata": {
        "id": "FRfZO_NZteRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7BS6ym3t-ae",
        "outputId": "148332f0-0da7-479d-99b2-1576b6443487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224994, 156707)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.sentiment, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yzMK8kzBueDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ_eeQQLuxFz",
        "outputId": "269577c3-2add-4af1-d4ef-76420816c07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((179995, 156707), (179995,))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CDWUyf2rovu",
        "outputId": "adb487ec-f297-4087-dad4-31e03cae87da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.702926731705149\n",
            "f1 score:  0.7437509584419568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing:"
      ],
      "metadata": {
        "id": "pyrf3kvxslYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization and Stopwords elimination:"
      ],
      "metadata": {
        "id": "397uYQ_gv-Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LemmaTokenizer(object):\n",
        "  def __init__(self):\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "  def __call__(self, document):\n",
        "    lemmas = []\n",
        "    for t in word_tokenize(document):\n",
        "      t = t.strip()\n",
        "      lemma = self.lemmatizer.lemmatize(t)\n",
        "      lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "\n",
        "lemmaTokenizer = LemmaTokenizer()\n",
        "vectorizer = TfidfVectorizer(tokenizer=lemmaTokenizer, stop_words=stopwords.words('english'))\n",
        "X_tfidf = vectorizer.fit_transform(df.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2-38h4LnXeM",
        "outputId": "a50f85e4-5ecb-4d91-fa86-99cc8bac4caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performances after lemmatization and stopwords elimination:\n",
        "\n"
      ],
      "metadata": {
        "id": "yejE8um3yruM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.sentiment, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "v5xxSZX2zEBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvRvjuMm1TC4",
        "outputId": "2db5ed24-aa55-4461-e46e-afd4e714884f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(179995, 173979)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCLFA5CfyWHn",
        "outputId": "0f114db2-7738-4ff6-e31d-267f255199c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6928820640458677\n",
            "f1 score:  0.7392256019322212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try stopword removal only:\n",
        "\n",
        "you can make a set of stopwords and remove some of the words using the remove function.\n",
        "\n",
        "stoplist = set(stopwords.words(\"english\")\n",
        "stoplist.remove('Not').\n",
        "\n",
        "You can then use this set to filter out the list of stopwords you want.\n",
        "\n"
      ],
      "metadata": {
        "id": "7cQW-gx1Dh21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X_tfidf = vectorizer.fit_transform(df.text)"
      ],
      "metadata": {
        "id": "vOxjiobP7ACP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3765437-a749-4c95-abc5-972fda50b1dd",
        "id": "AlQE1WWZ7ACP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224994, 156563)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.sentiment, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BeqbPWiO7ACP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccddcb0a-7686-45c5-dea8-6c0d6ce7fc42",
        "id": "rqYw4dx_7ACP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((179995, 156563), (179995,))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5106c9ba-8732-498a-db2a-ea06480d05ff",
        "id": "h1mYES-D7ACP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7093268739305318\n",
            "f1 score:  0.7520191104538733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's clear that lemmatization worsen the performances.. this can happen because abbreviations, like punctuation, can be relevant to sentiment detection.\n",
        "The problem is that default tokenization used by TfidfVectorizer explicitly ignores all punctuation.\n",
        "\n",
        "We can modify **token_pattern** in Tfidf_vectorizer to be any character except one or more whitespaces:\n",
        "\n"
      ],
      "metadata": {
        "id": "OKc53jWQDltJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), token_pattern=r'[^\\s]+')\n",
        "X_tfidf = vectorizer.fit_transform(df.text)\n",
        "print(\"Shape after tf-idf: \", X_tfidf.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.sentiment, test_size=0.2, random_state=42)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_KejCLPGVxz",
        "outputId": "b487b28d-d17f-4c6b-83ef-640bf5faa4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 263344)\n",
            "Accuracy:  0.7001488921976043\n",
            "f1 score:  0.7436594030814827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to modify the hyperparameters of the tf-idf model, we should tune \n",
        "\n",
        "\n",
        "1.   Term frequency weighting. Recall that the term frequency is the normalized count of terms in a given document. This value can be set to:\n",
        "• b - binary,\n",
        "• t or n - raw,\n",
        "• a - augmented,\n",
        "• l - logarithm,\n",
        "• d - double logarithm,\n",
        "• L - log average.\n",
        "\n",
        "2.   Document frequency weighting. Recall that the document frequency is the number of documents in a corpus that contain a given term. This value can be set to:\n",
        "• x or n - none,\n",
        "• f - idf,\n",
        "• t - zero-corrected idf,\n",
        "• p - probabilistic idf.\n",
        "3.   Document normalization. Each document is normalized so that all document vectors are turned into unit vectors. In doing so, we eliminate all information on the length of the original document; this masks some subtleties about longer documents. First, longer documents will — as a result of containing more terms — have higher term frequency values. Second, longer documents contain more distinct terms. The document normalization can be set to:\n",
        "• x or n - none,\n",
        "• c - cosine,\n",
        "• u - pivoted unique,\n",
        "• b - pivoted character length.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7PFUU0RWOK6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'tfidf__use_idf': (True, False),\n",
        "              'tfidf__min_df': [1, 2, 3],\n",
        "              'tfidf__stop_words': [stopwords.words('english'), None],\n",
        "              'tfidf__token_pattern': (r'[^\\s]+', '(?u)\\b\\w\\w+\\b')}\n",
        "\n",
        "pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
        "                    (\"clf\", DecisionTreeClassifier())])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, n_jobs=-1, verbose=1)\n",
        "\n",
        "# we randomly sample from the df to perform grid search in a less time\n",
        "red_df = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "grid_search.fit(red_df.text, red_df.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rlzGEtFOKGn",
        "outputId": "f0695cf9-5001-4c03-dfa2-c5b1359e717a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 120.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 2077, in fit_transform\n",
            "    X = super().fit_transform(raw_documents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1330, in fit_transform\n",
            "    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\", line 1221, in _count_vocab\n",
            "    \"empty vocabulary; perhaps the documents only contain stop words\"\n",
            "ValueError: empty vocabulary; perhaps the documents only contain stop words\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.67936344 0.68585294        nan        nan 0.64660667 0.6556733\n",
            "        nan        nan 0.68394123 0.68607487        nan        nan\n",
            " 0.65456205 0.66238501        nan        nan 0.67736327 0.68176348\n",
            "        nan        nan 0.65900737 0.66194088        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                       ('clf', DecisionTreeClassifier())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'tfidf__min_df': [1, 2, 3],\n",
              "                         'tfidf__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
              "                                                'our', 'ours', 'ourselves',\n",
              "                                                'you', \"you're\", \"you've\",\n",
              "                                                \"you'll\", \"you'd\", 'your',\n",
              "                                                'yours', 'yourself',\n",
              "                                                'yourselves', 'he', 'him',\n",
              "                                                'his', 'himself', 'she',\n",
              "                                                \"she's\", 'her', 'hers',\n",
              "                                                'herself', 'it', \"it's\", 'its',\n",
              "                                                'itself', ...],\n",
              "                                               None],\n",
              "                         'tfidf__token_pattern': ('[^\\\\s]+',\n",
              "                                                  '(?u)\\x08\\\\w\\\\w+\\x08'),\n",
              "                         'tfidf__use_idf': (True, False)},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgLVg2ULVAOC",
        "outputId": "2a505fdc-ebab-49a3-fdfb-d24f7b06fb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.686\n",
            "Best parameters set:\n",
            "\ttfidf__min_df: 2\n",
            "\ttfidf__stop_words: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "\ttfidf__token_pattern: '[^\\\\s]+'\n",
            "\ttfidf__use_idf: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V-T_Js6cVzBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other preprocessing:"
      ],
      "metadata": {
        "id": "OT8NrS0uSCnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad',':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed',':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused',\n",
        "          '$_$': 'greedy','@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused','<(-_-)>': 'robot', 'd[-_-]b': 'dj', \n",
        "          \":'-)\": 'sadsmile',';)': 'wink',';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}"
      ],
      "metadata": {
        "id": "21_AA7sISFAw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    processedText = []\n",
        "    \n",
        "    # Defining regex patterns.\n",
        "    urlPattern        = r\"(http|https|ftp)://[a-zA-Z0-9\\\\./]+\"\n",
        "    userPattern       = '@[^\\s]+'\n",
        "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
        "    sequencePattern   = r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern = r\"\\1\\1\"\n",
        "    \n",
        "    for tweet in text:\n",
        "        tweet = tweet.lower()\n",
        "        \n",
        "        # Replace all URls with 'URL'\n",
        "        tweet = re.sub(urlPattern,' URL',tweet)\n",
        "        # Replace all emojis.\n",
        "        for emoji in emojis.keys():\n",
        "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
        "        # Replace @USERNAME to 'USER'.\n",
        "        tweet = re.sub(userPattern,' USER', tweet)        \n",
        "        # Replace all non alphabets.\n",
        "        #tweet = re.sub(alphaPattern, \" \", tweet)\n",
        "        # Replace 3 or more consecutive letters by 2 letter.\n",
        "        #tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "        processedText.append(tweet)\n",
        "        \n",
        "    return processedText"
      ],
      "metadata": {
        "id": "Jfa3b7kYSLkC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_preproc = preprocess(list(df['text']))\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "AihJPy2NSXCG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(X_preproc)\n",
        "print(\"Shape after tf-idf: \", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkea2KPcScbX",
        "outputId": "85228131-9220-4742-e807-ff3e31065b19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 74271)\n",
            "Accuracy:  0.7055045667681504\n",
            "f1 score:  0.7492810655365522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), use_idf=False)\n",
        "X = vectorizer.fit_transform(X_preproc)\n",
        "print(\"Shape after tf-idf: \", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEKhda5JV_gs",
        "outputId": "49f48a88-6604-4155-b6d7-8b0fbe9bc4f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 74271)\n",
            "Accuracy:  0.7053934531878486\n",
            "f1 score:  0.7505973097544917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SlWEI-oFUsIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try linearSVC:"
      ],
      "metadata": {
        "id": "ocCo4EWVWyyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), use_idf=False)\n",
        "X = vectorizer.fit_transform(X_preproc)\n",
        "print(\"Shape after tf-idf: \", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y4KSsBgS6R2",
        "outputId": "139ea9c3-bbd7-4141-d6a8-286ef51abac7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 74271)\n",
            "Accuracy:  0.77397275495011\n",
            "f1 score:  0.8109725500399576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try Logistic regression:\n"
      ],
      "metadata": {
        "id": "KDjNgjHGa9X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(df.text)\n",
        "print(\"Shape after tf-idf: \", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "log_clf = LogisticRegression(max_iter = 5000, n_jobs=-1)\n",
        "log_clf.fit(X_train,y_train)\n",
        "y_pred = log_clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzTBSfEJYEbW",
        "outputId": "fc57c258-fcac-4bca-93cb-35d4bbf6b4bb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 156563)\n",
            "Accuracy:  0.7799062201382253\n",
            "f1 score:  0.818208516886931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(X_preproc)\n",
        "print(\"Shape after tf-idf: \", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "log_clf = LogisticRegression(max_iter = 5000, n_jobs=-1)\n",
        "log_clf.fit(X_train,y_train)\n",
        "y_pred = log_clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_pred=y_pred, y_true=y_test))\n",
        "print(\"f1 score: \", f1_score(y_pred=y_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqObsx_5Yj_Y",
        "outputId": "f97c2dd5-66e3-46f4-a9df-ab52d8a59fce"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after tf-idf:  (224994, 79164)\n",
            "Accuracy:  0.7757505722349386\n",
            "f1 score:  0.814021636963453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pi4oxAy5cR29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}